{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MECE 6397: Project 4\n",
    "\n",
    "Syam Evani <br>\n",
    "08/09/2025 <br>\n",
    "\n",
    "## <span style=\"color: blue;\">Introduction</span>\n",
    "\n",
    "###  Table of Contents\n",
    "1. [Part 1: Dataset Selection](#part-1)\n",
    "2. [Part 2: Prepare Dataset](#part-2)\n",
    "3. [Part 3: T-testing](#part-3)\n",
    "4. [Part 4: Model Creation](#part-4)\n",
    "\n",
    "My code for this project is included in three ways:\n",
    "- Embedded in portions with relevant discussion\n",
    "- Uploaded as part of this deliverable on Canvas\n",
    "- Available on a public github here: <a> https://github.com/Sam-v6/mece-6397-doe/tree/main/project4 <a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"part-1\"></a>\n",
    "## <span style=\"color: blue;\">Part 1: Dataset Selection</span>\n",
    "As an overly zealous NFL football fan, I often wonder about the statistical significance of various betting odds as predictors for what team will win the game. Thus I was interested in finding some accessible data (not getting too involved in API data calls and such but a simple csv) that contains NFL game outcomes and various betting data. I was able to locate a great dataset that included a plethora of data. This dataset summarizes every NFL game since 1999 to present day including the outcome, total points scored, various betting odds, where the game was played, what day it was played, whether it was a regular season or playoff game, along with a wealth of other data even diving into the playing surface, weather, etc. My ultimate goal with this data was to take some betting data and a few other factors to see how statistically significant they are in the home team winning the game.\n",
    "\n",
    "\n",
    "Dataset link: <a> https://github.com/nflverse/nfldata/blob/master/data/games.csv <a>. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"part-2\"></a>\n",
    "## <span style=\"color: blue;\">Part 2: Dataset preparation</span>\n",
    "\n",
    "To prepare the data I load it in and immediately drop several columns that I'm not interested in. These include things like game IDs, stadiums, coaches, players, etc. I also then cut out some games that haven't been played yet (2024 season) and eliminate any neutral site games as I want to evalute games where there is a clear away and home team.\n",
    "\n",
    "I select several features to evaluate including:\n",
    "- Type of game (regular season, playoff, conference championship)\n",
    "- Day of week game is played\n",
    "- Days away team has had to rest\n",
    "- Days home team has had to rest\n",
    "- Away moneyline\n",
    "- Home moneyline\n",
    "- Overall spread\n",
    "- Away spread odds\n",
    "- Home spread odds\n",
    "- Whether it is divisional game (are teams in the same division)\n",
    "- Playing surface\n",
    "- Temperature\n",
    "- Wind Speed\n",
    "\n",
    "I then go through the dataset and make sure I'm only evaluating data that has all of these features for every game. Some games since 1999 don't have all this recorded, hence, making this step neeeded. \n",
    "\n",
    "At this point I can categorize the data, shifting game type, weekday, and surface from their string formats to enumerations that I can actually process downstream. Finally I evalute the final score to determine if the home team lost (0) or won (1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['game_type', 'weekday', 'away_score', 'home_score', 'result', 'total',\n",
      "       'away_rest', 'home_rest', 'away_moneyline', 'home_moneyline',\n",
      "       'spread_line', 'away_spread_odds', 'home_spread_odds', 'total_line',\n",
      "       'under_odds', 'over_odds', 'div_game', 'surface', 'temp', 'wind'],\n",
      "      dtype='object')\n",
      "      game_type  weekday  away_score  home_score  result  total  away_rest  \\\n",
      "1892          1        7        13.0        16.0     3.0   29.0         14   \n",
      "1893          1        7        12.0        17.0     5.0   29.0          7   \n",
      "1894          1        7        18.0        21.0     3.0   39.0          6   \n",
      "1896          1        7         0.0        41.0    41.0   41.0          7   \n",
      "1897          1        7        31.0        28.0    -3.0   59.0          7   \n",
      "\n",
      "      home_rest  away_moneyline  home_moneyline  ...  away_spread_odds  \\\n",
      "1892          7          -107.0          -103.0  ...            -112.0   \n",
      "1893          7           119.0          -129.0  ...             113.0   \n",
      "1894          7           300.0          -330.0  ...             106.0   \n",
      "1896         14           293.0          -323.0  ...            -103.0   \n",
      "1897          7          -369.0           339.0  ...             100.0   \n",
      "\n",
      "      home_spread_odds  total_line  under_odds  over_odds  div_game  surface  \\\n",
      "1892             104.0        33.5      -103.0     -107.0         0        0   \n",
      "1893            -121.0        34.5      -106.0     -104.0         0        0   \n",
      "1894            -114.0        41.0      -102.0     -108.0         1        1   \n",
      "1896            -105.0        39.0       100.0     -110.0         0        1   \n",
      "1897            -108.0        46.5      -106.0     -104.0         0        0   \n",
      "\n",
      "      temp  wind  home_team_win  \n",
      "1892  68.0   7.0              1  \n",
      "1893  58.0  11.0              1  \n",
      "1894  82.0   6.0              1  \n",
      "1896  82.0  15.0              1  \n",
      "1897  62.0   2.0              0  \n",
      "\n",
      "[5 rows x 21 columns]\n",
      "      game_type  weekday  away_score  home_score  result  total  away_rest  \\\n",
      "6699          3        6        10.0        34.0    24.0   44.0          7   \n",
      "6700          3        6        21.0        24.0     3.0   45.0          6   \n",
      "6702          3        7        27.0        24.0    -3.0   51.0          8   \n",
      "6703          4        7        17.0        10.0    -7.0   27.0          7   \n",
      "6704          4        7        31.0        34.0     3.0   65.0          7   \n",
      "\n",
      "      home_rest  away_moneyline  home_moneyline  ...  away_spread_odds  \\\n",
      "6699         14           330.0          -425.0  ...            -115.0   \n",
      "6700         13           360.0          -470.0  ...            -112.0   \n",
      "6702          6           120.0          -142.0  ...            -110.0   \n",
      "6703          8           180.0          -218.0  ...            -110.0   \n",
      "6704          8           260.0          -325.0  ...            -120.0   \n",
      "\n",
      "      home_spread_odds  total_line  under_odds  over_odds  div_game  surface  \\\n",
      "6699            -105.0        44.0      -105.0     -115.0         0        1   \n",
      "6700            -108.0        50.5      -105.0     -115.0         0        1   \n",
      "6702            -110.0        45.5      -108.0     -112.0         0        0   \n",
      "6703            -112.0        44.0      -105.0     -115.0         0        1   \n",
      "6704             100.0        52.5      -110.0     -110.0         0        1   \n",
      "\n",
      "      temp  wind  home_team_win  \n",
      "6699  27.0  16.0              1  \n",
      "6700  59.0   8.0              1  \n",
      "6702  25.0  11.0              0  \n",
      "6703  47.0   7.0              0  \n",
      "6704  69.0   5.0              1  \n",
      "\n",
      "[5 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Purpose: Project 4 - ML analysis on nfl betting info to determine wins\n",
    "Author: Syam Evani\n",
    "\"\"\"\n",
    "\n",
    "# Standard imports\n",
    "import os\n",
    "\n",
    "# Additional imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.stats import f\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.stats import t, ttest_ind\n",
    "\n",
    "# Local imports\n",
    "# None\n",
    "\n",
    "#----------------------------------------------------\n",
    "# Load data\n",
    "#----------------------------------------------------\n",
    "data = pd.read_csv(os.path.join(os.getenv('USERPROFILE'),'repos','mece-6397-doe','project4','data','games.csv'))\n",
    "\n",
    "# There's alot of superflous data we don't want to draw predictions from, let's drop these\n",
    "drop_list = [\"week\", \"gameday\", \"gametime\", \"old_game_id\", \"gsis\", \"nfl_detail_id\", \n",
    "             \"pfr\", \"pff\", \"espn\", \"ftn\", \"away_qb_id\", \"home_qb_id\", \"away_qb_name\", \n",
    "             \"home_qb_name\" , \"away_coach\", \"home_coach\", \"referee\", \"stadium_id\", \"stadium\",\n",
    "             \"overtime\", \"season\", \"away_team\", \"home_team\", \"roof\"]\n",
    "data = data.drop(columns=drop_list)\n",
    "\n",
    "# This dataset includes games that haven't been played yet, filter out 2024 games as well as any neutral site games\n",
    "data = data[~data['game_id'].str.contains(\"2024\", na=False)]\n",
    "data = data[~data['location'].str.contains(\"Neutral\", na=False)]\n",
    "data = data.drop(columns=['game_id'])\n",
    "data = data.drop(columns=['location'])\n",
    "\n",
    "# Feature selection\n",
    "selected_features = ['game_type', 'weekday', 'away_rest', \n",
    "                     'home_rest', 'away_moneyline','home_moneyline',\n",
    "                     'spread_line', 'away_spread_odds', \"home_spread_odds\", \n",
    "                     \"div_game\", \"surface\", \"temp\", \"wind\"]\n",
    "\n",
    "# Drop rows with missing data in any of the selected features columns\n",
    "data = data.dropna(subset=selected_features)\n",
    "\n",
    "# Check on our data and see what factors we are considering now\n",
    "print(data.columns)\n",
    "\n",
    "#----------------------------------------------------\n",
    "# Categorize data\n",
    "#----------------------------------------------------\n",
    "# Clean up data to go from strings to enumerations\n",
    "cleanup_nums = {\n",
    "                \"game_type\": {\"REG\": 1, \"WC\": 2, \"DIV\":3, \"CON\":4, \"SB\":5},\n",
    "                \"weekday\": {\"Monday\": 1, \"Tuesday\":2, \"Wednesday\":3, \"Thursday\":4, \"Friday\":5, \"Saturday\":6, \"Sunday\":7},\n",
    "                \"surface\": {\"sportturf\":0, 'astroplay':0, 'grass':1, 'fieldturf':0, 'dessograss':1, 'a_turf':0, 'astroturf':0, 'grass ':1},\n",
    "                }\n",
    "data = data.replace(cleanup_nums)\n",
    "\n",
    "# Create a new column based on the 'result' column\n",
    "data['home_team_win'] = np.where(data['result'] > 0, 1, 0)\n",
    "\n",
    "# Print data\n",
    "print(data.head())\n",
    "print(data.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"part-3\"></a>\n",
    "## <span style=\"color: blue;\">Part 3: T-testing</span>\n",
    "\n",
    "I slice my data into the usual 80% for training and 20% for testing with our selected features with the home team victory status as the target.\n",
    "\n",
    "In the same fashion as the sample code I perform a T-testing with one minor modification to record whether or not the specific feature is significant in impacting the outcome for the home team (based on if the p value is below 0.05 and if the absolute value of the t value is larger than the critical t value)\n",
    "\n",
    "\n",
    "Results are shown below:\n",
    "\n",
    "| Feature          | Significant?   | T-statistic          | P-value                  | Critical T-value       |\n",
    "|------------------|----------------|----------------------|--------------------------|------------------------|\n",
    "| surface          | SIGNIFICANT    | -3.7055993914058156  | 0.0002144236330758636    | -1.6453250802533461    |\n",
    "| wind             | Not important  | -0.024027255376345074| 0.9808323511483465       | -1.6453250802533461    |\n",
    "| game_type        | Not important  | 1.7626017611319151   | 0.07806215295834043      | -1.6453250802533461    |\n",
    "| weekday          | Not important  | -0.15812049374843445 | 0.8743717271701335       | -1.6453250802533461    |\n",
    "| away_rest        | SIGNIFICANT    | -2.3750130051411737  | 0.017606345955603387     | -1.6453250802533461    |\n",
    "| home_rest        | Not important  | 0.974192675505116    | 0.33003376365095805      | -1.6453250802533461    |\n",
    "| away_moneyline   | SIGNIFICANT    | 21.884464420578997   | 4.078382882439177e-99    | -1.6453250802533461    |\n",
    "| home_moneyline   | SIGNIFICANT    | -20.612840525524433  | 8.492000533979854e-89    | -1.6453250802533461    |\n",
    "| spread_line      | SIGNIFICANT    | 23.14438175202809    | 8.727713364946639e-110   | -1.6453250802533461    |\n",
    "| away_spread_odds | SIGNIFICANT    | -6.146854246433647   | 8.869240168908078e-10    | -1.6453250802533461    |\n",
    "| home_spread_odds | SIGNIFICANT    | 3.9606055931091095   | 7.637211505173663e-05    | -1.6453250802533461    |\n",
    "| div_game         | SIGNIFICANT    | -2.6049679456009094  | 0.009230384202277137     | -1.6453250802533461    |\n",
    "| temp             | Not important  | -1.7575713625833678  | 0.07891510083042995      | -1.6453250802533461    |\n",
    "\n",
    "\n",
    "Not suprising (at least for myself as fan of typically bad NFL teams and used to seeing dreadful predicted spreads for my team to lose), betting stats have a strong signficance in prediciting the outcome of the game. Interstingly, the surface of the playing field is rather important, indicating for example the home team's winning probabilty is signifcantly lower on turf compared to playing on grass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "T Results\n",
      "-------------------------------------------\n",
      "Not important: T-test results for 'game_type': t-statistic=1.7626017611319151, p-value=0.07806215295834043, critical t-value=-1.6453250802533461\n",
      "Not important: T-test results for 'weekday': t-statistic=-0.15812049374843445, p-value=0.8743717271701335, critical t-value=-1.6453250802533461\n",
      "SIGNIFICANT: T-test results for 'away_rest': t-statistic=-2.3750130051411737, p-value=0.017606345955603387, critical t-value=-1.6453250802533461\n",
      "Not important: T-test results for 'home_rest': t-statistic=0.974192675505116, p-value=0.33003376365095805, critical t-value=-1.6453250802533461\n",
      "SIGNIFICANT: T-test results for 'away_moneyline': t-statistic=21.884464420578997, p-value=4.078382882439177e-99, critical t-value=-1.6453250802533461\n",
      "SIGNIFICANT: T-test results for 'home_moneyline': t-statistic=-20.612840525524433, p-value=8.492000533979854e-89, critical t-value=-1.6453250802533461\n",
      "SIGNIFICANT: T-test results for 'spread_line': t-statistic=23.14438175202809, p-value=8.727713364946639e-110, critical t-value=-1.6453250802533461\n",
      "SIGNIFICANT: T-test results for 'away_spread_odds': t-statistic=-6.146854246433647, p-value=8.869240168908078e-10, critical t-value=-1.6453250802533461\n",
      "SIGNIFICANT: T-test results for 'home_spread_odds': t-statistic=3.9606055931091095, p-value=7.637211505173663e-05, critical t-value=-1.6453250802533461\n",
      "SIGNIFICANT: T-test results for 'div_game': t-statistic=-2.6049679456009094, p-value=0.009230384202277137, critical t-value=-1.6453250802533461\n",
      "SIGNIFICANT: T-test results for 'surface': t-statistic=-3.7055993914058156, p-value=0.0002144236330758636, critical t-value=-1.6453250802533461\n",
      "Not important: T-test results for 'temp': t-statistic=-1.7575713625833678, p-value=0.07891510083042995, critical t-value=-1.6453250802533461\n",
      "Not important: T-test results for 'wind': t-statistic=-0.024027255376345074, p-value=0.9808323511483465, critical t-value=-1.6453250802533461\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#----------------------------------------------------\n",
    "# Slice data into training and testing sets\n",
    "#----------------------------------------------------\n",
    "# Split training data\n",
    "X = data[selected_features]\n",
    "y = data['home_team_win']\n",
    "\n",
    "# Create a StandardScaler object\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit and transform the data\n",
    "X_normalized = scaler.fit_transform(X)\n",
    "\n",
    "# Splitting data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_normalized, y, test_size=0.2, random_state=42)\n",
    "\n",
    "#----------------------------------------------------\n",
    "# T-test\n",
    "#----------------------------------------------------\n",
    "t_results = {}\n",
    "print(\"-------------------------------------------\")\n",
    "print(\"T Results\")\n",
    "print(\"-------------------------------------------\")\n",
    "for feature in selected_features:\n",
    "    win = data[data['home_team_win'] == 1][feature]\n",
    "    loss = data[data['home_team_win'] == 0][feature]\n",
    "    \n",
    "    # Calculate t-test statistic and p-value\n",
    "    t_stat, p_value = ttest_ind(win, loss)\n",
    "    \n",
    "    # Calculate critical t-value from t-distribution\n",
    "    n1 = len(win)\n",
    "    n2 = len(loss)\n",
    "    dof = n1 + n2 - 2  # Degrees of freedom for independent two-sample t-test\n",
    "    critical_t = t.ppf(0.05, dof)  # Using 0.05 significance level\n",
    "    \n",
    "    if p_value < 0.05 and abs(t_stat) > critical_t:\n",
    "        print(f\"SIGNIFICANT: T-test results for '{feature}': t-statistic={t_stat}, p-value={p_value}, critical t-value={critical_t}\")\n",
    "    else:\n",
    "        print(f\"Not important: T-test results for '{feature}': t-statistic={t_stat}, p-value={p_value}, critical t-value={critical_t}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"part-4\"></a>\n",
    "## <span style=\"color: blue;\">Part 4: Model creation</span>\n",
    "\n",
    "Drawing on our first homework assignment, I used multiple regression models including linear, decision tree, random forest, SVR, and KNN to build models and evalute how a collection of all of our features (even those that were not significant for the first process of building the model) could perform. Results are shown below. For this specific collection of features the best model would actually be simple linear regression.\n",
    "\n",
    "| Model | Value |\n",
    "|-------|-------|\n",
    "| lr    | 0.21056065180003614 |\n",
    "| dtr   | 0.4188562596599691  |\n",
    "| rfr   | 0.2356763523956723  |\n",
    "| svr   | 0.25144313085577946 |\n",
    "| knn   | 0.24500772797527048 |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "Model Results\n",
      "-------------------------------------------\n",
      "{'lr': 0.21056065180003614, 'dtr': 0.4188562596599691, 'rfr': 0.2356763523956723, 'svr': 0.25144313085577946, 'knn': 0.24500772797527048}\n"
     ]
    }
   ],
   "source": [
    "#----------------------------------------------------\n",
    "# Model developement\n",
    "#----------------------------------------------------\n",
    "models = {}\n",
    "results = {}\n",
    "\n",
    "# Train different models\n",
    "models[\"lr\"] = LinearRegression().fit(X_train, y_train)\n",
    "models[\"dtr\"] = DecisionTreeRegressor().fit(X_train, y_train)\n",
    "models[\"rfr\"] = RandomForestRegressor().fit(X_train, y_train)\n",
    "models[\"svr\"] = SVR().fit(X_train, y_train)                         # Default rbf kernel, 3 degree polynomial kernel function, uses 1/(n_features) * X.var()) as gamma\n",
    "models[\"knn\"]  = KNeighborsRegressor().fit(X_train, y_train)        # By default will use 5 neighbors\n",
    "\n",
    "# Predict and calculate MSE\n",
    "for regressor in models:\n",
    "    y_pred = models[regressor].predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "    # Store the results\n",
    "    results[regressor] = mse\n",
    "\n",
    "print(\"-------------------------------------------\")\n",
    "print(\"Model Results\")\n",
    "print(\"-------------------------------------------\")\n",
    "print(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
