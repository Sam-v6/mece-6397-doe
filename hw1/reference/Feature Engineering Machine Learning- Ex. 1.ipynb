{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Integrating Design of Experiments (DoE) for feature engineering with machine learning involves systematically exploring combinations of features to understand their impact on model performance. Here, we'll go through a simple example using Python, where we'll apply a factorial design from the DoE to explore the effects of different feature transformations on a regression model's performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Scenario\n",
    "\n",
    "- Let's say we have a dataset with three features (X1, X2, X3) and we want to understand how different transformations (e.g., logarithmic, square root, and square) applied to these features affect the performance of a linear regression model.\n",
    "\n",
    "- We'll use a 2-level factorial design, considering the presence or absence of each transformation as the two levels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Required Libraries\n",
    "- pandas for data handling.\n",
    "- numpy for numerical operations.\n",
    "- sklearn for machine learning models and data splitting.\n",
    "- pyDOE2 or pyDOE for generating factorial design matrices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Generate the Design Matrix\n",
    "First, we need to create a design matrix for our experiments, representing all combinations of the transformations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [2. 0. 0.]\n",
      " [3. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 1. 0.]\n",
      " [2. 1. 0.]\n",
      " [3. 1. 0.]\n",
      " [0. 2. 0.]\n",
      " [1. 2. 0.]\n",
      " [2. 2. 0.]\n",
      " [3. 2. 0.]\n",
      " [0. 3. 0.]\n",
      " [1. 3. 0.]\n",
      " [2. 3. 0.]\n",
      " [3. 3. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 1.]\n",
      " [2. 0. 1.]\n",
      " [3. 0. 1.]\n",
      " [0. 1. 1.]\n",
      " [1. 1. 1.]\n",
      " [2. 1. 1.]\n",
      " [3. 1. 1.]\n",
      " [0. 2. 1.]\n",
      " [1. 2. 1.]\n",
      " [2. 2. 1.]\n",
      " [3. 2. 1.]\n",
      " [0. 3. 1.]\n",
      " [1. 3. 1.]\n",
      " [2. 3. 1.]\n",
      " [3. 3. 1.]\n",
      " [0. 0. 2.]\n",
      " [1. 0. 2.]\n",
      " [2. 0. 2.]\n",
      " [3. 0. 2.]\n",
      " [0. 1. 2.]\n",
      " [1. 1. 2.]\n",
      " [2. 1. 2.]\n",
      " [3. 1. 2.]\n",
      " [0. 2. 2.]\n",
      " [1. 2. 2.]\n",
      " [2. 2. 2.]\n",
      " [3. 2. 2.]\n",
      " [0. 3. 2.]\n",
      " [1. 3. 2.]\n",
      " [2. 3. 2.]\n",
      " [3. 3. 2.]\n",
      " [0. 0. 3.]\n",
      " [1. 0. 3.]\n",
      " [2. 0. 3.]\n",
      " [3. 0. 3.]\n",
      " [0. 1. 3.]\n",
      " [1. 1. 3.]\n",
      " [2. 1. 3.]\n",
      " [3. 1. 3.]\n",
      " [0. 2. 3.]\n",
      " [1. 2. 3.]\n",
      " [2. 2. 3.]\n",
      " [3. 2. 3.]\n",
      " [0. 3. 3.]\n",
      " [1. 3. 3.]\n",
      " [2. 3. 3.]\n",
      " [3. 3. 3.]]\n",
      "Number of Design: 64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from pyDOE3 import fullfact\n",
    "\n",
    "# Define the levels for each factor (transformation)\n",
    "# Features X1, X2, X3 -- three of them\n",
    "# 0: No transformation, 1: Logarithmic, 2: Square root, 3: Square\n",
    "levels = {0: lambda x: x, 1: np.log, 2: np.sqrt, 3: np.square}\n",
    "\n",
    "# Generating a full factorial design for 3 factors, each with 4 levels\n",
    "# Note: For simplicity, using 2 levels in the example; for actual implementation, adjust as needed\n",
    "design = fullfact([4, 4, 4])\n",
    "\n",
    "# Show the design matrix\n",
    "print(design)\n",
    "\n",
    "print(f\"Number of Design:\",len(design))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Apply Transformations and Train Models\n",
    "Next, we'll apply the transformations indicated by each row in the design matrix to our dataset, train a model using these transformed features, and evaluate its performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample dataset\n",
    "# Replace this with your actual dataset\n",
    "X = np.random.rand(100, 3)  # 100 samples, 3 features\n",
    "y = 2*X[:, 0] + 3*np.log(X[:, 1] + 1) + np.sqrt(X[:, 2])  # Sample target variable\n",
    "\n",
    "# Splitting the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Placeholder for results and best transformed features\n",
    "results = []\n",
    "best_transformed_features = None\n",
    "\n",
    "for i in range(len(design)):\n",
    "    # Apply transformations based on the design matrix\n",
    "    X_train_transformed = np.column_stack([levels[design[i, j]](X_train[:, j]) for j in range(X.shape[1])])\n",
    "    X_test_transformed = np.column_stack([levels[design[i, j]](X_test[:, j]) for j in range(X.shape[1])])\n",
    "    \n",
    "    # Train a linear regression model\n",
    "    model = LinearRegression().fit(X_train_transformed, y_train)\n",
    "    \n",
    "    # Predict and calculate MSE\n",
    "    predictions = model.predict(X_test_transformed)\n",
    "    mse = mean_squared_error(y_test, predictions)\n",
    "    \n",
    "    # Store the results\n",
    "    results.append((design[i], mse, X_test_transformed))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note\n",
    "\n",
    "- Remember to adjust the levels and transformations according to your specific dataset and problem.\n",
    "-  Also, consider the computational complexity as the number of combinations grows exponentially with the number of features and levels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Finding the Lowest Design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Design with lowest MSE: [0. 2. 2.], MSE: 0.0026593118867547804\n",
      "Feature values for the design with the lowest MSE:\n",
      "[[0.21287848 0.89284169 0.80967701]\n",
      " [0.53437872 0.65283742 0.85057783]\n",
      " [0.86428178 0.65784915 0.95877706]\n",
      " [0.28919683 0.68819965 0.9487926 ]\n",
      " [0.27465762 0.87845614 0.572646  ]\n",
      " [0.62087092 0.27896845 0.62637442]\n",
      " [0.63716396 0.81903539 0.58439643]\n",
      " [0.67230801 0.72890961 0.20830536]\n",
      " [0.17555217 0.5968805  0.93052659]\n",
      " [0.71228632 0.55011094 0.7413942 ]\n",
      " [0.10488506 0.26799024 0.80380426]\n",
      " [0.41854678 0.52060351 0.76465364]\n",
      " [0.17286088 0.44776715 0.80769637]\n",
      " [0.04261646 0.72164784 0.35284987]\n",
      " [0.8697459  0.84124473 0.92554505]\n",
      " [0.98658139 0.97650932 0.70901763]\n",
      " [0.92243139 0.74783776 0.68592767]\n",
      " [0.42158544 0.93336789 0.53665428]\n",
      " [0.02093944 0.31207888 0.35896485]\n",
      " [0.92723778 0.67549112 0.81582949]]\n"
     ]
    }
   ],
   "source": [
    "# Find the design with the lowest MSE\n",
    "min_mse_design, min_mse, best_transformed_features = min(results, key=lambda x: x[1])\n",
    "\n",
    "# Print the design, MSE, and feature values with the lowest error\n",
    "print(f\"Design with lowest MSE: {min_mse_design}, MSE: {min_mse}\")\n",
    "print(\"Feature values for the design with the lowest MSE:\")\n",
    "print(best_transformed_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Summary:\n",
    "\n",
    "### There exist multiple sets of features for the design with the lowest MSE in the example code since it relates to how transformations are applied and evaluated:\n",
    "\n",
    "1) Transformation Matrix: For each design in the factorial experiment, a specific combination of transformations is applied to each feature. The transformations (e.g., logarithmic, square root, square) modify how the features contribute to the model, potentially uncovering interactions or nonlinear relationships that aren't visible with the original features.**\n",
    "\n",
    "2) Full Dataset Application: The transformations are applied to all instances (rows) in the test dataset. This results in a new set of feature values for each design, across all test samples. Thus, for each design, ther# e isn't just a single transformed feature value, but rather a full matrix of transformed features corresponding to each instance in the test dataset.**\n",
    "\n",
    "3) Model Training and Testing: Each set of transformed features (i.e., each matrix from the test dataset corresponding to a design) is used to train and then predict using the model. The performance of the model with these transformed features is assessed (in this case, using MSE).**\n",
    "\n",
    "4) Display of Multiple Feature Values: When the script prints \"Feature values for the design with the lowest MSE,\" it shows the transformed feature values for all the instances in the test dataset that were used in the experiment resulting in the lowest MSE. This isn't just a single row or a single set of transformations; it's an entire matrix showing how each sample was transformed under the optimal experimental conditions identified.**\n",
    "\n",
    "**This comprehensive view allows you to see how each transformation impacts the dataset and contributes to the model's performance, providing insights into how different feature engineering strategies can be optimized in a machine learning workflow.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
